# -*- coding: utf-8 -*-
"""pandas_stats.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13F3rJWJREiZEs_FmsqOPLyVgtkH_9Spe
"""

import pandas as pd
import os
import csv
from google.colab import drive
import math
from collections import Counter, defaultdict
import os

drive.mount('/content/drive')

fb_posts = '/content/drive/My Drive/Presidential Election Data/2024_fb_posts_president_scored_anon.csv'
fb_ads = '/content/drive/My Drive/Presidential Election Data/2024_fb_ads_president_scored_anon.csv'
tw_posts = '/content/drive/My Drive/Presidential Election Data/2024_tw_posts_president_scored_anon.csv'

def analyze_dataset(df):
    print("===== General Dataset Summary =====")

    for col in df.columns:
        print(f"\nColumn: {col}")
        col_data = df[col].dropna()

        if pd.api.types.is_numeric_dtype(col_data):
            print(f"  Count: {col_data.count()}")
            print(f"  Mean: {col_data.mean()}")
            print(f"  Min: {col_data.min()}")
            print(f"  Max: {col_data.max()}")
            print(f"  Stddev: {col_data.std()}")
        else:
            print(f"  Count: {col_data.count()}")
            print(f"  Unique values: {col_data.nunique()}")
            if not col_data.empty:
                most_freq = col_data.mode().iloc[0]
                freq_count = col_data.value_counts().iloc[0]
                print(f"  Most frequent: {most_freq} (appears {freq_count} times)")

df_ads = pd.read_csv(fb_ads)
df_ads = df_ads.replace(' ', pd.NA)  # Treat empty strings as NA
# Convert numeric columns automatically
df_ads = df_ads.apply(pd.to_numeric, errors='ignore')
analyze_dataset(df_ads)

"""## Grouped Aggregation"""

import pandas as pd

def analyze_grouped_dataset(df, group_cols):
    print(f"\n===== Grouped Analysis by {group_cols} =====")

    grouped = df.groupby(group_cols)

    for i, (group_key, group_df) in enumerate(grouped):
        if i >= 3:
            break  # Limit to first 3 groups

        print(f"\nGroup: {group_key}")
        for col in group_df.columns:
            if col in group_cols:
                continue  # Skip group keys

            col_data = group_df[col].dropna()
            print(f"  Column: {col}")

            if pd.api.types.is_numeric_dtype(col_data):
                print(f"    Count: {col_data.count()}")
                print(f"    Mean: {col_data.mean()}")
                print(f"    Min: {col_data.min()}")
                print(f"    Max: {col_data.max()}")
                print(f"    Stddev: {col_data.std()}")
            else:
                print(f"    Count: {col_data.count()}")
                print(f"    Unique values: {col_data.nunique()}")
                if not col_data.empty:
                    most_freq = col_data.mode().iloc[0]
                    freq_count = col_data.value_counts().iloc[0]
                    print(f"    Most frequent: {most_freq} (appears {freq_count} times)")

analyze_grouped_dataset(df_ads, ['page_id'])
analyze_grouped_dataset(df_ads, ['page_id', 'ad_id'])

